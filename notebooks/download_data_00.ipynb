{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyreadr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar los conjuntos de dato\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prima Indias Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prima_indians_diabetes_url = \"https://nrvis.com/data/mldata/pima-indians-diabetes.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se usa el comando \" ! \" para escribir comandos que escribirias en la terminal\n",
    "!wget -O ../data/prima-indians-diabetes.csv { prima_indians_diabetes_url } -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = pd.read_csv(\n",
    "    \"../data/prima-indians-diabetes.csv\", # or prima_indisas_diabetes_url\n",
    "    sep=\",\",\n",
    "    #El dataset venia sin nombrar las columnas por tal motivo es necesario hacerlo manual\n",
    "names = [\n",
    "    \"pregnancies\",  # embarazos\n",
    "    \"glucose\",  # glucosa\n",
    "    \"blood_pressure\",  # presion_sanguinea\n",
    "    \"skin_thickness\",  # espesor_piel\n",
    "    \"insulin\",  # insulina\n",
    "    \"bmi\",  # bmi\n",
    "    \"diabetes_pedigree_function\",  # funcion_pedigree_diabetes\n",
    "    \"age\",  # edad\n",
    "    \"outcome\",  # resultado\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naniar (oceanbuoys, pedestrian, riskfactors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear unidades de información de los conjuntos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://github.com/njtierney/naniar/raw/master/data/\"\n",
    "datasets_names = (\"oceanbuoys\", \"pedestrian\", \"riskfactors\")\n",
    "extension = \".rda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descargar y cargar los conjuntos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['oceanbuoys_df', 'pedestrian_df', 'riskfactors_df'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diccionario para almacenar los DataFrames de los conjuntos de datos\n",
    "datasets_dfs = {}\n",
    "\n",
    "# Iterar sobre los nombres de los conjuntos de datos\n",
    "for dataset_name in datasets_names:\n",
    "\n",
    "    # Construir nombres de archivo y URL para el conjunto de datos actual\n",
    "    dataset_file = f\"{ dataset_name }{ extension }\"\n",
    "    dataset_output_file = f\"../data/{ dataset_file }\"\n",
    "    dataset_url = f\"{ base_url }{ dataset_file }\"\n",
    "    \n",
    "    # Descargar el conjunto de datos desde la URL y guardar en el directorio ../data/\n",
    "    !wget -q -O { dataset_output_file } { dataset_url }\n",
    "\n",
    "    # Leer el conjunto de datos desde el archivo usando pyreadr y almacenarlo en el diccionario\n",
    "    datasets_dfs[f\"{ dataset_name }_df\"] = pyreadr.read_r(dataset_output_file).get(dataset_name)\n",
    "\n",
    "# Mostrar las claves (nombres) de los DataFrames almacenados en el diccionario\n",
    "datasets_dfs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### incluir conjunto de datos en nuestro ambiente local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "locals().update(**datasets_dfs)\n",
    "del datasets_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificar carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La data Ocean buoys tiene un tamaño de: (736, 8)\n",
      "La data Peatonas tiene un tamaño de: (37700, 9)\n",
      "La data Factores de riesgo tiene un tamaño de: (245, 34)\n",
      "La data Diabetes tiene un tamaño de: (768, 9)\n",
      "Carga de datos exitosa\n"
     ]
    }
   ],
   "source": [
    "print(f\"La data Ocean buoys tiene un tamaño de: {oceanbuoys_df.shape}\", \n",
    "      f\"La data Peatonas tiene un tamaño de: {pedestrian_df.shape}\", \n",
    "      f\"La data Factores de riesgo tiene un tamaño de: {riskfactors_df.shape}\", \n",
    "      f\"La data Diabetes tiene un tamaño de: {diabetes_df.shape}\",\n",
    "      sep=\"\\n\"\n",
    "      \n",
    ")\n",
    "\n",
    "print(\"Carga de datos exitosa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_datos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
